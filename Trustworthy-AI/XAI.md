# XAI (Explainable AI) - 설명가능한 인공지능 

### XAI
인공지능 모델이 특정 결론을 내리기까지 어떤 근거로 의사 결정을 내렸는지를 알 수 있게 설명 가능성을 추가하는 비법으로 머신러닝과 연관된 사람이 시스템을 신뢰하기 위해 사용된다. 인공지능에 설명 능력을 부여해 기계와 인간이 상호작용에 합리성을 확보하는 것이다. 

XAI는 인공지능 연구원들이 인공지능을 개선하기 위해 사용할 수 있을 뿐만 아니라 비 전문가들과 소통하기 위한 수단이 될 수 있다. 비 전문가들은 XAI를 통해 인공지능을 **신뢰**할 수 있는 근거를 확보할 수 있다. 

* 해석가능한 인공지능 (Interpretable AI)
* 투명한 인공지능 (Transparent AI)

### DARPA 지침

* 기존 머신러닝 모델에 설명 가능한 기능 추가
  + 기존 머신러닝 동작 방식을 충분히 이해하고 있어야 할 뿐 아니라, 의미 정보에 대한 특성을 함께 모델에 삽입해야 하기 때문에 문제 해결하기 어렵다.  
* 머신러닝 모델에 HCI (Human Computer Interaction) 기능 추가
* XAI를 통한 현재 상황이 개선

### XAI 구현 방법 

#### 구현 방법 1

* 현재 문재룰 해결하는 머신러닝 모델을 만든다.
* 설명가능한 모델을 결합한다.
* 모델의 결과를 해석하는 인터페이스를 연결한다.
* 모델의 문제점을 발견하고 개선한다.
* 모델을 테스트하고 평가하는 파이프라인을 만든다.

#### 구현 방법 2  (궁극적인 방법)

* 구현 방법 1을 설명하는 이론적 기반을 마련한다.
* 앞의 이론적 기반을 뒷받침할 수 있는 계산 모델 (Computational Model)을 만든다.
* 모델을 검증한다. 

#### DARPA에서 셜명하는 XAI 프로젝트의 미래 

* DARPA의 Explaination Interface 
  + 머신러닝 모델이 왜 특정 행동을 하는지 설명할 수 있고 
  + 왜 의도한 대로 동작하지 않는지에 관한 근거를 제시
  
  + I understand why. (근거를 이해합니다.)
  + I understand why not. (왜 안되는지 이해합니다)
  + I know when you'll succeed. (성공할 시점을 한다)
  + I know when you'll fail. (실패할 시점을 한다)
  + I know when to trust you. (믿을 시점을 안다)
  + I know why you erred (왜 잘못했는지 안다)

## References

[1] 안재현, 설명가능한 인공지능, 인공지능을 해부하다. 
